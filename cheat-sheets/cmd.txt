Темы:
* man
* sudo
* dd
* fdisk
* Скачать, передать (scp, wget)
* Patch (diff)
* ISO
* Процессы в фоновом режиме
* Полезные команды и трюки
* apt и dpkg
* Журналы dmesg и journalctl
* strace
* indent форматирование и выравнивание
* mount
* sync
* Смена каталога, относительные и абсолютные пути
* Символические и жесткие ссылки
* Сигналы с помощью команды kill
* Выполнить сценарий при старте системы
* Crontab
* X clipboards
* Копирование с помощью cp
* lsattr и chattr
* /etc/skel
* umask
* update-initramfs
* shred и wipe
* Как добавить шрифт для терминала
* tree
* Удаление директории


--- man
There’s a kernel of truth in the old Unix joke, "the only command you need to know is man."

1. Главные пользовательские команды
2. Системные вызовы
3. Библиотека функции С
4. Устройства и сетевые интерфейсы
5. Формат файла
6. Игры
7. Смешанные файлы
8. Стандартные операции ядра Linux

Маны хранятся обычно в сжатом виде `.gz` по пути `/usr/share/man/man-N`
Для создания man используется определенный синтаксис, язык.

Для того чтобы узнать какой man предоставляет утилита:
$ whatis stdout

Поиск по ключевому слову:
$ man -k unistd
$ man -k '[a-z]' | grep '(3)'
$ man -K PRIx32
$ man -wK PRIx32
$ man -f open
$ man 0 stdio.h
$ man 3 stdio

Поиск 'chdir':
$ man -k [a-z] | grep '(2)' | grep 'change'

Если man не ищется:
$ sudo mandb


--- sudo
$ sudo id            # выполнение программы от суперпользователя
$ sudo -u <user> id  # выполнение программы id от builder
$ sudo -i            # вход в оболочку root, меняет PWD (login shell)
$ sudo -i -u <user>  # вход в оболочку builder (login shell)
$ sudo -s            # (shell) вызывает SHELL (/bin/bash) не меняет PWD (non login shell)
$ su                 # вход root, не хватает /sbin/ в PATH (non login shell)
$ su -               # вход (будто новый вход), скудный env (login shell)
$ su - <user>        # аналогично, скудный env (login shell)


--- dd
Осуществляет копирование только на низкоуровневом уровне (аналог `cp`).
Утилита читает и записывает данные блоками, причем размер блока
может изменяться с помощью параметра bs (по умолчанию идет 512кб).

bs=size размер блока (кол-во байт)
можно писать как bs=1024, а можно bs=1k
count=num кол-во блоков

Например команда:
$ dd if=/dev/zero of=new_file bs=8000 count=2
из /dev/zero читается 8000 байт в файл new_file дважды
то есть сумма файла будет 16000 байт

$ dd if=file1 of=file2 bs=2 count=1
будет скопировано содержимое файла `file1` в `file2` равному 2 байт
здесь важно не забыть count=1

Создание 10 файлов весом 5M, обязательно наличие `count`
$ for i in $(seq 10); do dd if=/dev/zero of=file_$i count=$i bs=5M; done
Некоторые используют файл `/dev/urandom`, но это долго и бесмысленно.

Клонирование жесткого диска:
$ dd if=/dev/sda of=dev/sdb bs=4096

Запись образа на устройство флешки:
$ dd if=full_path.iso of=/dev/sdb bs=4M status=progress oflag=sync
$ dd if=full_path.iso of=/dev/sdb bs=4M status=progress; sync

Забить нулями SSD диск - это удалит всю ОС (если HDD лучше использовать `shred`):
$ dd if=/dev/zero of=/dev/sda bs=512 count=1
$ shred -vfz /dev/sda


--- fdisk
$ fdisk -l        # показать весь список - лист
$ fdisk /dev/sdc  # создание
p                 # вывод разделов
n                 # создание разделов
d                 # удаление
w                 # записать новую таблицу разделов на диск
t                 # изменение типа раздела (EFI, BIOS, SWAP, FAT32, etc), обычно передается b / 83
q                 # выйти без сохранения


--- Скачать, передать (scp, wget)
$ scp user@ip:file.txt .            # взять с узла файл и скопировать в текущую директорию
$ scp file.txt user@ip:~/           # скопировать файл с текущего хоста на другой узел
$ scp -r                            # параметр -r (копирование директории)

$ wget ftp://server/path/to/file    # скачать только файл
$ wget -r ftp://server/path/to/dir  # скачать директорию, рекурсивно (со всеми подкаталогами)

Скачать только директорию vagrant/ без остальных папок:
$ wget -r -nH --cut-dirs=1 --no-parent ftp://10.77.111.111/packages/vagrant
-nH (no host directories)

Скачать файл в /tmp директорию с FTP:
$ wget -P /tmp ftp://server/path/to/file

Скачать содержимое веб-сайта:
$ wget -r -l0 -nH gplaycards.com

Получить код состояния:
$ wget -O/dev/null -q ftp://192.168.32.24/upload
-O (файлы в /dev/null - не скачивать)
-q заглушить вывод

или
$ curl -IsSf "$1" > /dev/null 2>&1


--- Patch (diff)
Патчи нужны для модификации существующего ПО, работа с исходными кодами проекта. Вообще, все
программисты в процессе своей совместной работы над проектом обмениваются исключительно отдельными
правками, а не пересылают друг другу актуальные версии проектов целиком. Сама правка, текстовые
изменения в исходном коде проектов и есть патч или "заплатка". Патч содержит не только новые
изменения, но и служебную информацию, нужную для установки этого патча. Таким образом,
патч - это текстовый файл определенного формата, содержащий в себе данные и инструкции для
привидения конечного файла (или проекта) к нужному или актуальному виду.

patchfile генерируется с помощью `diff`

Можно сгенерировать patch-diff файл таким образом:
$ diff Orig Update > patch
$ diff -ruN Orig Update > patch
$ patch Orig < patch                              # поднять Orig до состояния patch
$ patch -R Orig < patch                           # отменить изменения в Orig (откат)

$ diff -Naur OrigDir/ UpdateDir/ > project-patch
$ diff -ruN OrigDir/ UpdateDir > project-patch    # без файлов .git и подобных
$ diff -r a/ b/                                   # дифф каталогов делается через ключ -r
$ diff -ruN --exclude='.git' OrigDir/ UpdateDir/  # игнорировать .git директорию

Работа с проектами, есть `orig/src/file`:
$ cp -r orig/ dupl/

Изменения:
dupl/new
dupl/src/file
dupl/src/aaa

$ diff -Naur orig/ dupl/ > project-path
если нужно пропатчить `orig` до состояние `dupl`
$ cd orig && patch -p1 < ../project-path

Если патч оказался бесполезным, тогда можно откатить:
$ patch -p1 -R < ../project-patch

При возникновении ошибок, начнут появляться файлы `*.rej`.
Чтобы сделать восстановление содержимого (если сломали)
можно перед этим делать $ patch -b -p1 < ../project-patch
Тогда будет копия этих файлов с расширением `.orig`.

`*.rej` файлы описывают куски, которые не получается применить.
`*.orig` файлы создаются для того, чтобы сохранить оригинальный вид,
потому что текущий исходник (например `main.c`) изменился,
а `main.c.orig` остался прежним.

Если patch не получилось применить, можно открыть `.rej` файл и сравнить
с оригинальным файлом, найти различия, и подправить `<...>.patch` файл.
Затем снова попробовать, либо можно попробовать $ patch -p0 < file.rej

Если `dpkg-source --commit` все равно не хочет принимать исправленный патч,
можно создать копию текущей директории без `.orig` файлов, применить в оригинальной
директории патч, а затем сделать $ diff -aur clean/ myorig/ > a.patch

Показать различия с номерами строк:
$ diff -c a b

Показать разницу построчно:
$ sdiff a b | less


--- ISO
Можно сделать extract готового образа в директорию (без монтирования):
$ 7z x file.iso         # извлечь содержимое образа в текущую директорию
$ 7z x -odir/ file.iso  # извлечь содержимое образа в директорию <dir>

Изменить какие-то файлы или модули, а затем:
$ genisoimage -o new_file.iso dir/ * # создает диск с ФС iso9660

Создать диск с файловой системой EXT4, например, нужно выделить для ФС 5Gb:
$ dd if=/dev/zero of=image.iso bs=1G count=5  # создаст файл 5GB

$ mkfs.ext4 image.iso   # создаст ext4 ФС
$ file image.iso        # убедиться что файл имеет ФС ext4
$ mount image.iso /mnt  # монтирование, можно заполнять данными (выполняется от sudo)


--- Процессы в фоновом режиме
$ xlogo &  # в фоновой режим, на задний план
$ ps
$ jobs     # задания
$ jobs -p  # pid фонового процесса

Чтобы вернуть на передний план:
$ fg %1 - номер задания и он вернет на передний план, затем ^C (прервать)
$ bg %1 - переводит в фоновой режим, на задний план, ^Z (остановить)


--- Полезные команды и трюки
awk:
$ echo "one two" | awk '{print $1}'                          # вывод только первой колонки
$ echo "one two three" | awk '{print $3,$1}'                 # вывод только 3 и 1 колонки
$ echo "one two" | awk '{print "text: " $3,$1}'              # вывод text: <колонки>
$ echo "one two three four" | awk '{print $NF}'              # выводит последнее значение

tr:
$ echo "hello" | tr -d "he"                                  # удаляет 'he' символы, выводит 'llo'
$ echo " space" | tr -d [:space:]                            # удаляет пробелы
$ echo "1 please 2 remove 3 all 4 digits" | tr -d [:digit:]  # удаляет все цифры
$ cat /etc/passwd | tr ":" " "                               # заменить ":" на " "
$ cat /dev/urandom | tr -dc '0-9'                            # -c бинарное представляет в читабельном виде
$ cat /etc/passwd | tr [:lower:] [:upper:]                   # из lowercase в uppercase

sed:
$ sed 's/user/AAA/' /etc/passwd                              # меняет user на AAA
$ sed '3d' /etc/passwd                                       # удаление 3 строки
$ sed '3,$d' passwd                                          # удалить с 3 строки всё остальное
$ sed -i '$d' passwd                                         # удалить последнюю строку в файле
$ sed -i "s/hello/new/" passwd                               # заменить в самом файле hello на new
$ cat /etc/passwd | sed -n 2p                                # получить вторую строку

grep:
$ ps aux | grep nginx                # нечисто
$ ps aux | grep '[n]ginx'            # вывод конкретного процесса
$ grep -i "user" file                # не учитывать регистр, искать USER и user
$ grep "[0-9]" /var/log/file         # найдем строки только с цифрами
$ grep -r "hello" /var/log/          # рекурсивный поиск слова hello во всех файлах /var/log
$ grep -n "user" /etc/passwd         # номер строки совпадения
$ grep --color                       # добавляет цвета в вывод
$ grep -E "user|root" passwd         # аналог команды выше
$ grep "bash$" /etc/passwd           # найти строки, которые заканчиваются bash
$ grep -r --include="*.c" "yes"      # грепать только в си файлах
$ grep -- "---"                      # греп черточек
$ grep -o user /etc/passwd           # выводит не все строки, а только совпадения
$ grep -rl 'pattern'                 # показывает файлы в которых нашелся паттерн

find:
$ find . -name "file"                             # найти по имени file
$ find . -iname "file"                            # не обращать внимание на регистр
$ find . -type d                                  # искать толко директории
$ find . -type f                                  # искать только файлы
$ find . -maxdepth 1                              # углубленность поиска
$ find /tmp -user "root"                          # искать файлы по владельцу
$ find / -name "*.sh"                             # искать файлы с расширением .sh
$ find . -not -name "file"                        # найти все файлы, кроме file
$ find /tmp -type f -exec cat {} \;               # найти файлы и прочитать их
$ find /tmp -type f -exec ls -ld {} \;            # найти файлы и вывести их разрешения
$ find /tmp -type f -empty                        # найти пустые файлы
$ find . -type f -exec rm -rf {} \;               # удалить все файлы
$ find / -size +1G                                # найти файлы больше 1G
$ find . -type f -delete                          # удалить все файлы
$ find /tmp/aaa -mindepth 1 -delete               # удаляет и файлы и каталоги (без текущего каталога /tmp/aaa)
$ find / -perm -u=s                               # найти setuid файлы
$ find / -inum <inode>                            # найти inode
$ find /var/* -type d -exec ls -1td {} +          # вывести последние измененные директории
$ find . -name "*.png" -o -name "*.jpg"           # показать все 'png' и 'jpg' форматы
$ find . -name "*.orig" -not -path "./.pc/*"      # искать *.orig, но игнорировать .pc/*
$ find . -name "*.i686.rpm" -exec mv {} ../ww/ \; # переместить все *.i686.rpm файлы в ../w

Можно искать не только f / d, но и l / b / c / s / p
ссылки, блочные устройства, символьные устройства, каналы, сокеты.

tar:
$ tar -cvzf hello-2.10.tar.gz hello-2.10
$ tar -cvJf hello-2.10.tar.xz hello-2.10
$ tar -cvjf hello-2.10.tar.bz2 hello-2.10
$ tar -xvzf hello-2.10.tar.gz
-c # создает
-x # наоборот
$ tar -xvzf a.tgz -C /tmp

-v # подробный вывод
-z # сжатие (gzip)
-J # сжатие (xz)
-f # указать файл
-C # перейти в /tmp каталог

$ tar --list -f hello-2.10.tar.gz

Интересная опция `--sparse`.
Используется для оптимизации архивирования файлов, которые содержат большое количество нулевых
байтов или нулевых блоков. Когда эта опция включена, tar будет обрабатывать эти нулевые блоки более
эффективно, что позволяет сэкономить место на диске и ускорить процесс архивирования.

ar:
$ ar t hello_2.10-2_amd64.deb         # выводит содержимое
$ ar x hello_2.10-2_amd64.deb         # делает extract
$ ar cr main.archive a.o b.o          # создает архив, -c (create), -r (replace)

Положить файлы в deb архив:
$ ar r deb debian-binary control.tar.xz data.tar.xz

Файл `debian-binary` содержит версию пакета, а `control.tar.xz` и `data.tar.xz`
содержат метаданные и данные пакета соответственно.

tail:
$ tail file                           # показать последние 10 строк
$ tail -f file                        # отслеживать изменения
$ tail -1 file                        # прочитать последнюю строку

head:
$ head file                           # первые 10 строк
$ head -1 file                        # первая строка
$ head -c 8                           # 8 символов (в строку) $ cat /dev/urandom | head -c 8

gzip:
$ gzip file                           # сжатие
$ gzip -l file.gz                     # содержимое архива
$ zcat file.gz                        # просмотр сжатого файла

gunzip:
$ gunzip file.gz                      # наоборот

tee:
$ ls | tee a b c                      # запись вывода в несколько файлов
$ echo "good" | sudo tee -a /secret   # запись в привилегированный файл, -a (append)
$ ls | tee file &>/dev/null           # убрать вывод


--- apt-get, apt и dpkg
Утилита apt-cache используется для работы с кэшем базы данных пакетов (package cache)
пакетного менеджера apt. Примеры:
$ apt-cache depends <pack>   # только зависимости
$ apt-cache policy <pack>    # версия пакета + источники
$ apt-cache search vim       # поиск пакета (более минималистично)
$ apt-cache search ^vim$     # поиск пакета (например по шаблону)
$ apt-cache show <pack>      # описание пакета (control)
$ apt-cache showsrc <pack>   # описание исходника (dsc - debian source control)
$ apt-cache madison <pack>   # доступные версии

Выводит ссылки на исходные пакеты из репозитория sid без скачивания:
$ apt-get -t sid source --print-uris --only-source <pkg>

Получить ссылки пакета:
$ apt-get source --print-uris <pkg>

$ apt search <pack>          # поиск пакета
$ apt serch <pack> | less    # поиск пакета
$ apt list                   # все доступные пакеты

`dpkg` стоит рассматривать как низкоуровневый инструмент (движок), а `apt` - как инструмент,
более близкий к пользователю. Эти инструменты работают совместно. `dpkg` ничего не скачивает,
он занимается пакетами, которые уже есть в системе.

Например: `at` тянет за собой разные почтовые пакеты, `at` их рекомендует - можно не ставить:
$ apt-get install at --no-install-recommends

$ apt-get install --download-only <pack>  # без установки
$ apt-get source --compile <pack>         # скачать + скомпилировать, но не подтягивает Build-Depends
$ apt-get install <pack> <pack>-          # установить пакет и одновременно удалить еще пакет
$ apt-get --purge remove <pack> <pack>+   # удалит и установит curl одновременно
$ apt-get --reinstall install <pack>      # переустановить пакет
$ apt-get install <pack>/unstable         # установить пакет из ветки unstable
$ apt-get remove <pack>                   # удаление пакета + зависимостей, но оставит в системе настроечные файлы
                                          # при удалении пакета Debian конфигурационные файлы сохраняются
                                          # в целях облегчения возможной повторной установки
$ apt-get --purge remove <pack>           # полное удаление пакета с их настроечными файлами

Одинаковые команды:
$ apt-get purge <pack>
$ apt-get --purge remove <pack>
Файлы, которые создались пользователем все равно не удалятся.

$ apt-get -u upgrade
# обновление пакетов, опция -u показывает полный список пакетов предназначенных для обновления
# без этой опции, обновление будет вслепую
# upgrade не удаляет, не разрешает конфликты и т.д, только обновляет их

$ apt-get install --only-upgrade neovim
# обновить конкретный пакет

$ apt-get -u dist-upgrade
# обновление нового выпуска, обновление всей системы
# разрешение конфликтов, обновление важных пакетов, удаление ненужных пакетов, интеллектуальная система
# а система upgrade полегче - просто поднимает пакеты

$ apt-get source <pack>                   # получить исходник, не нужны права суперпользователя
$ apt-get build-dep <pack>                # подтягивает Build-Depends
$ apt-get clean                           # удаляет весь `/var/cache/apt/archives`
$ apt-get autoclean                       # удаляет только ненужные файлы
$ apt-get autoremove                      # удаляет ненужные пакеты (которые автоматически поставились)
$ apt-get changelog <pack>                # показывает changelog пакета
$ apt edit-sources                        # редактирование sources.list

$ dpkg -I <path_to_deb>                   # информация пакета
$ dpkg --contents <path_to_deb>           # показывает содержимое пакета
$ dpkg -L <pack>                          # содержимое пакета (то распакованное)
$ dpkg -S stdio.h                         # найти пакет, которому принадлежит файл stdio.h
$ dpkg -S $(which scp)                    # найти пакет, которому принадлежит утилита scp
$ dpkg --search $(which scp)              # или так (нужно указать полный путь)
$ dpkg -S /usr/include/stdio.h
$ dpkg -l | grep <pack>                   # установлен ли пакет в системе
$ dpkg -s <pack>                          # информация пакета
$ dpkg -i --debug=77777 <path_to_deb>     # debug
$ dpkg -c <pack>                          # содержимое пакета
$ dpkg-query -s vim                       # узнать размер пакета

$ dpkg -i <path_do_deb>                   # установка пакета
# этот этап делится на:
$ dpkg --unpack <path_to_deb>             # делает extract (распаковывает) пакета (архивы) в корень
$ dpkg --configure <path_to_deb>          # настраивает пакет

# dpkg хранит журнал в `/var/log/dpkg.log`.
# `/var/lib/dpkg/status` хранит информацию о пакетах.
# `/var/lib/dpkg/info` хранит различные скрипты, файлы пакетов.


--- Журналы dmesg и journalctl
Системный журнал, `/var/log/journal/*`
$ journalctl -f                           # в реальном времени
$ journalctl -S today                     # сегодня
$ journalctl -S today -p err              # сегодня err уровень
$ journalctl -S today -p 3..4             # сегодня err, warning
$ journalctl -u <name>.service            # показывает журнал конкретного сервиса

Системный журнал ядра, `/var/log/kern.log` или напрямую из ядра.
$ dmesg -T                                # читабельный формат
$ dmesg -w                                # в реальном времени
$ dmesg -H                                # less
$ dmesg -x                                # показывает уровень (приоритет)
$ dmesg -HTx


--- strace
$ strace a.out
$ strace -o log a.out                     # вывод в файл log
$ strace -p <pid>                         # конкретно <pid>
$ strace bash -c 'cd /tmp'                # отследить встроенную команду

Например, не проходит команда `mount -t nfs ...`
$ strace -o mount.strace -s1024 -f -i -k -n mount -t nfs <path> <to-path>

-s1024 означает, что strace будет полный, а не 32 длиной
-f отслеживать так же дочерние процессы (если они будут созданы)
-i указатель инструкции во время системного вызова
-k трассировка выполнения отслеживаемых процессов
-n номер системного вызова


--- indent форматирование и выравнивание
$ indent -br -ce <file.c>  # with spaces
$ indent -linux <file.c>   # same, but with tabs


--- mount
Linux работает по принципу иерархического дерева каталогов, где корневой каталог (/) является
основной точкой монтирования, в которую по умолчанию входят все остальные.

Системные разделы монтируются автоматически при старте системы. Если нужно подключить дополнительные
разделы, в некоторыех случаях, может понадобиться делать это вручную.

В Unix процесс присоединения файловой системы называется монтированием.
Разбор вывода mount, например: proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)
* Устройство (но не все являются устройствами, например proc)
* Слово on
* Точка монтирования (где будет находится фс)
* Слово type
* Тип файловой системы, краткий идентификатор
* Параметры монтирования

В файле `/etc/fstab` можно посмотреть информацию о смонтированных разделах. Данный файл читается на
этапе загрузки системы. В файле `/etc/mtab` (символьная ссылка) файл в котором есть таблица
смонтированных ФС.

Монтировать ФС, лучше в `/mnt` или `/media`.
В `/mnt` находятся временные ФС (на время примонтировали, поработали и убрали).
А в `/media` хранятся монтированные съемные носители (флешки, диски).

$ mount -a                        # примонтировать все устройства, описанные в fstab
$ mount -t ext4 <dev> <path>      # указать тип ФС
$ mount -o ro <dev> <path>        # примонтировать read-only (можно еще использовать rw)
$ mount --bind /mnt /media/mnt    # можно примонтировать одну папку в другую,
                                  # если НЕ использовать --bind -> (is not a block device)
$ mount file.iso /mnt             # монтирование ФС (file.iso, образ диска)

Иногда при размонтировании ФС, может появиться ошибка (target is busy).
В этом случае можно посмотреть:
$ lsof -w <path>
$ lsof -w /dev/sdc1
Выведит программы, которые используют эту ФС / устройство.

А если всё равно нужно отмонтировать (директорию используют программы login):
$ umount -l /path/to
$ umount -f /path/to

Для более красивого вывода, лучше использовать:
$ findmnt # дерево
$ findmnt -l # список
$ findmnt -t ext4 # ФС ext4


--- sync
Всё что хранилось в памяти, буферах, кэшах, будет записано на диск, предотвращается потеря данных.
Ядро хранит данные в памяти во избежание частых (обычно медленных) дисковых операций чтения и
записи. Это повышает производительность, но если компьютер аварийно завершает работу, данные могут
быть утеряны, либо может быть повреждена файловая система. sync гарантирует, что все, что
хранилось в памяти, будет записано на диск.

В секции `buff/cache` команды `free -h` можно увидеть кол-во используемой памяти
и вот она будет сброшена на диск.

sync лучше делать перед dd / umount устройства:
$ sync; umount /mnt
$ sync; dd ...

Так как это обеспечит более надежное сохранение данных на диск. Команда `sync` гарантирует, что все
данные, находящиеся в оперативной памяти, будут записаны на диск перед тем как размонтировать
файловую систему.

Команда `sync` в Linux предназначена для записи данных из кэша (включая буфер и кэш страниц) на
диск. Однако она не очищает кэш и буферы. То есть, после выполнения команды `sync`, данные остаются
в кэше, но они уже записаны на диск, что обеспечивает их сохранность в случае отключения питания или
сбоя. Поэтому, если вы используете команду `sync` и затем проверяете секцию `buff/cache` с помощью
команды `free -h`, вы не увидите уменьшения этой секции. Это нормальное поведение.


--- Смена каталога, относительные и абсолютные пути
Мы прописываем change directory + pathname(путь, маршрут)
$ cd /var/log/nginx

Пути могут быть абсолютными и относительными. Абсолютный путь начинается с корневого каталога и
перечисляет ветви дерева, например надо войти в каталог `bin/`, для этого надо прописать абсолютный
путь `/usr/bin`.

Относительный путь - это путь который начинается с текущего каталога. Например мы находимся в папке
`/usr/bin` и нужно перейти в `/usr`, можно прописать абсолютный путь `cd /usr`, либо можно прописать
относительный `../`. Либо находимся в `/usr` и нужно попасть в `/usr/bin` можно прописать абсолютный,
что намного дольше, либо прописать относительный `cd ./bin`

cd - сменить рабочи каталог на предыдущий
cd ~ сменить рабочий каталог на домашний


--- Символические и жесткие ссылки
`ln password fun` - создание жесткой ссылки(hardlink), указывает только на файлы, не может
указывать на каталоги затем если посмотреть `inode` этих двух файлов - он будет одинаков
и если удалить целевой файл, то вторая ссылка не станет "битой" и сохраняет содержимое файла.
Здесь важно заметить что при создании hardlink не создается новый тип файла, а создается
regular file. Создание жесткой ссылки не получится сделать если файл находится в другом разделе.
Файлы должны быть на одном разделе, иначе получаем ошибку - 'Invalid cross-device link'.

Символическую ссылку можно создавать на другие разделы.
`ln -s dir/ dir` - создание символической ссылки(symlink), ссылка на каталог или файл здесь
создается специальный тип файла - ссылка, которая просто указывает на другую сущность в системе если
удалить целевой каталог, то ссылка станет "битой". Так же символическая ссылка может ссылаться на
удаленные компьютеры и на другие разделы.

Команда `chmod` для symlink не устанавливается, если задать новые права доступа, то они
распределяться на родителя symlink.

Если удалить файл до того, как будет удалена символическая ссылка, ссылка останется на месте, но
будет указывать в никуда. О таких ссылках говорят, что они битые. Если прописать `ls`, то битая
ссылка будет гореть красным.


--- Сигналы с помощью команды kill
Команда `kill` используется для убийства, то есть для завершения процессов, принудительно завершить
выполнение вышедней из-под контроля программы, отвергающей любые другие попытки закрыть ее.

Например
$ xlogo &
$ kill 28401 - принудительно убивает процесс

А команда `killall` позволяет убить несколько процессов:
$ xlogo & xlogo &
$ killall xlogo - убивает все xlogo

$ kill -9 vs kill <pid>
Если передать сигнал -9 (SIGKILL) это говорит ОС перестать запускать процесс.
Если без -9 (просто SIGTERM) это делает вежливый запрос на удаление процесса.

Сигнал -KILL или (-9) нужно использовать в крайне редких случая, так как он оставляет процессы
сироты и загрязнает память, лучше всего использовать по дефолту -TERM, сигнал -9 нужно отправлять,
когда не сработал -TERM Если нужно отправить конкретный сигнал, то надо сделать `kill -l`.

Послать определенный сигнал можно так:
$ kill -s SIGALRM $(pidof a.out)


--- Выполнить сценарий при старте системы
Можно использовать `crontab` и прописать:
@reboot  /path/to/script.sh

А можно использовать `/etc/xdg/autostart/example.desktop`.
Будет выполнен после входа в графическое окружение:
[Desktop Entry]
Type=Application
Exec=/usr/local/bin/script.sh
Terminal=false
StartupNotify=false
Name=
Comment=

А можно использовать `/etc/rc.local` сценарий, написать сценарий:
$ chmod +x /etc/rc.local
$ systemctl enable rc-local
$ systemctl start rc-local
$ /etc/rc.local enable

В данном сценарии должно быть
#!/bin/sh -e
exit 0


--- Crontab
Системный демон, используемый для выполнении задач в фоновом режиме в указанное время.
Демон называтеся `cron`, а `crontab` - это команды.

$ crontab -e  # редактирование файла расписания для конкретного пользователя
$ crontab -l  # вывод содержимого для конкретного пользователя

# Порядок
minute(s) hour(s) day(s) month(s) weekday(s) command(s)
-> https://crontab.guru/

Окружение crontab:
HOME=/home/myuser
LOGNAME=myuser
PATH=/usr/bin:/bin
LANG=ru_RU.UTF-8
SHELL=/bin/sh
PWD=/home/myuser

Пример:
@reboot sleep 10 && ~/.local/bin/mygit.sh pull
Скрипт `mygit.sh` подтягивает изменения в проектах, `sleep 10` установлен для того,
чтобы DNS/SSH успели подняться (нужно для `git pull`).

Еще есть такие трюки:
@reboot ~/.profile; ~/.local/bin/script.sh
Если не устраивает скудное окружение `crontab`, можно вставить пользовательское.


--- X clipboards
* Primary
Старый и традиционный вид буфера.
Копирование в Primary: с помощью мыши.
Вставка из Primary: Middle click, Shift + insert

* Clipboard
Более современный буфер обмена.
Копирование в Clipboard: Ctrl + C
Вставка из Clipboard: Ctrl + V

* Secondary
Используется реже и имеет меньшее значение в повседневной работе.
Его использование зависит от конкретных приложений и инструментов.

Примеры команд:
$ xsel -b -c
$ xsel -p -c
$ xsel -b -i
$ xsel -p -i


--- Копирование с помощью cp
Копирование скрытных файлов:
$ cp -r /etc/skel/. /home/dir
$ cp -rT /etc/skel /tmp/home

Копирование вместе с родителем:
$ cp -r --parents /var/log /backup
-> /backup/var/log


--- lsattr и chattr
Например, необходимо ограничить доступ к файлу (запрет удаления, переименования).
Можно добавить биты с помощью `chmod` и `chown`, но это не идеальное решение, root все же
имеет полный доступ к файлу. С помощью `chattr` можно устанавливать и отключать атрибуты
файлов на уровне ФС независимо от стандартных чтение, запись, выполнение. Такие трюки
поддерживают ФС семейства ext (ext2, ext3, ext4), NFS не поддерживает immutable files.
Символы '+', '-', '=' - работают аналогично `chmod` команде.

$ touch <file>
$ lsattr <file>
--------------e------- a
Флаг 'e' в выводе команды lsattr показывает, что файл имеет установленный атрибут "extended
attributes" (дополнительные атрибуты). Это означает, что можно использовать команду `chattr` для
добавления или изменения дополнительных атрибутов для этого файла.

$ chattr =i <file>
<file>: Operation not permitted

Можно воспользоваться:
$ sudo chattr =i <file>

или

Трюк с CAP_LINUX_IMMUTABLE:
$ sudo setcap cap_linux_immutable+ep /usr/bin/chattr
$ chattr =i <file>
$ rm <file>           # а фигушки (EPERM)
$ sudo rm <file>      # а фигушки (EPERM)
$ mv <file> new       # а фигушки (EPERM)
$ sudo mv <file> new  # а фигушки (EPERM)
$ sudo setcap -r /usr/bin/chattr


--- /etc/skel
$ useradd -m user -s /bin/bash
-m, создает домашний каталог пользователю, но иногда в чрутах это может не работать.
Поэтому приходится вручную создавать домашний каталог и копировать файлы из `/etc/skel`.
Эти . файлы описывают дефолтное поведение shell пользователя .bashrc и подобные.
$ mkdir /home/<user>
$ cp -r /etc/skel/. /home/<user>


--- umask
Пользовательская маска, используется для присвоения определенных прав доступа по умолчанию при
создании файла или каталога.

$ umask a=rx,ug+w      # установка 002
$ umask -S             # покажет установленные perms

Файлы считаются: 666 - umask, например: (666 - 2 = 664)
Директории считаются: 777 - 22 (22 это umask)

https://wintelguy.com/umask-calc.pl


--- update-initramfs
Генерирует `initrd.img`, `update-initramfs` запускает `initramfs-tools` сценарий
`/etc/kernel/postinst.d/initramfs-tools`

Для обновления initrd образа нужно выполнить `update-initramfs`
$ update-initramfs -u -k all          # для всех ядер (не рекомендуется)
                                      # может сломаться, и затем ядро не запустится
$ update-initramfs -u -k $(uname -r)  # для текущего

Как разархивировать initrd:
$ cp /boot/initrd.img-$(uname -r) .
$ zcat initrd.img-5.10.176-1-generic | cpio -idmv

Наоборот:
$ find | cpio -o -H newc > ../initrd_new
$ gzip initrd_new


--- shred и wipe
$ shred -u -z <file>  # уничтожить файл (-u (remove), -z (add zeros))
$ shred /dev/sda      # уничтожить весь диск

`shred` не работает с каталогами, для них использовать `wipe`:
$ wipe -rf <dir>


--- Как добавить шрифт для терминала
Скачать шрифт и положить его в директорию ~/.fonts
$ fc-cache -fv # обновить кэш
$ fc-list | grep "my font" # проверить доступность
В терминале выбрать данный шрифт.


--- tree
$ tree /path/to/directory
$ tree -h    # размеры файлов
$ tree -L 2  # глубина файлов


--- Удаление директории
Удалит директорию:
$ rm -rf dir/

Выдаст ошибку если директория не пуста:
$ rmdir dir/

Приглушить вывод ошибки, но директория не удалится:
$ rmdir --ignore-fail-on-non-empty dir/ 2>/dev/null
